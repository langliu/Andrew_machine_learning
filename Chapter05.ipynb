{
 "cells" : [
  {
   "cell_type" : "markdown",
   "metadata" : {
    "collapsed" : true,
    "pycharm" : {
     "name" : "#%% md\n"
    }
   },
   "source" : [
    "# 多变量线性回归"
   ]
  },
  {
   "cell_type" : "markdown",
   "source" : [
    "## 多功能\n",
    "\n",
    "|Size($feet^2$)|Number of bedrooms|Number of floors|Age of home(years)|Price($1000)|\n",
    "|--|--|--|--|--|\n",
    "|2104|5|1|45|460|\n",
    "|1416|3|2|40|232|\n",
    "|1534|3|2|30|315|\n",
    "|852|2|1|36|178|\n",
    "|...|...|...|...|...|\n",
    "\n",
    "*概念*\n",
    "\n",
    "- n = 样本特征数量\n",
    "- $x^{(i)}$ = 第i个训练样本的特征向量\n",
    "- $x^{(i)}_j$ = 第i个训练样本的特征向量的第j个特征值\n",
    "\n",
    "表达为数学的假设如下：\n",
    "\n",
    "$ h_\\theta(x) = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\theta_3x_3 + \\theta_4x_4 $\n",
    "\n",
    "推广至多元线性回归：\n",
    "\n",
    "$ h_\\theta(x) = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\theta_3x_3 + ... + \\theta_nx_n $"
   ],
   "metadata" : {
    "collapsed" : false
   }
  },
  {
   "cell_type" : "markdown",
   "source" : [
    "## 多元梯度下降法\n",
    "\n",
    "假设: $ h_\\theta(x) = \\theta^Tx = \\theta_0 + \\theta_1x_1 + \\theta_2x_2 + \\theta_3x_3 + ... + \\theta_nx_n $\n",
    "\n",
    "参数：$ \\theta_0,\\theta_1,...,\\theta_n$\n",
    "\n",
    "代价函数： $J(\\theta_0,\\theta_1,...,\\theta_n) = \\frac{1}{2m} \\sum_{i=1}^m (h_\\theta(x^{(i)})-y^{(i)})^2$\n",
    "\n",
    "![](http://andrew-machine-learning.oss-cn-hangzhou.aliyuncs.com/20200305200418.png)"
   ],
   "metadata" : {
    "collapsed" : false
   }
  },
  {
   "cell_type" : "markdown",
   "source" : [
    "## 多元梯度下降法——特征缩放\n",
    "\n",
    "![](http://andrew-machine-learning.oss-cn-hangzhou.aliyuncs.com/20200305225904.png)\n",
    "\n",
    "一般来说，在运用梯度下降法的时候我们会将特征的取值约束到-1到1的范围内，\n",
    "\n",
    "![](http://andrew-machine-learning.oss-cn-hangzhou.aliyuncs.com/20200305230517.png)"
   ],
   "metadata" : {
    "collapsed" : false
   }
  },
  {
   "cell_type" : "markdown",
   "source" : [
    "## 多元梯度下降法——学习率\n",
    "\n",
    "用于判断梯度下降是否收敛\n",
    "\n",
    "![](http://andrew-machine-learning.oss-cn-hangzhou.aliyuncs.com/20200305233303.png)"
   ],
   "metadata" : {
    "collapsed" : false
   }
  },
  {
   "cell_type" : "markdown",
   "source" : [
    "## 正规方程\n",
    "\n",
    "$ \\theta = (X^TX)^-1X^Ty $\n",
    "\n",
    "$ \\theta = minJ_{(\\theta)}$\n",
    "\n",
    "对于特征项较小的数据集来说，正规方程一般由于梯度下降法（n<10000）\n"
   ],
   "metadata" : {
    "collapsed" : false
   }
  }
 ],
 "metadata" : {
  "kernelspec" : {
   "display_name" : "Python 3",
   "language" : "python",
   "name" : "python3"
  },
  "language_info" : {
   "codemirror_mode" : {
    "name" : "ipython",
    "version" : 2
   },
   "file_extension" : ".py",
   "mimetype" : "text/x-python",
   "name" : "python",
   "nbconvert_exporter" : "python",
   "pygments_lexer" : "ipython2",
   "version" : "2.7.6"
  },
  "pycharm" : {
   "stem_cell" : {
    "cell_type" : "raw",
    "source" : [ ],
    "metadata" : {
     "collapsed" : false
    }
   }
  }
 },
 "nbformat" : 4,
 "nbformat_minor" : 0
}